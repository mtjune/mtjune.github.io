---
layout: post
title:  "自己符号化器"
date:   2015-12-01 02:00:00 +0900
categories: DeepLearning
---
Deep Learning勉強会 第4回


# 5.1 概要

自己符号化器はニューラルネットにおいて，目標とする出力(正解データ)を入力と同じにした教師なし学習を行うときに用いられるモデル．

自己符号化器の中間層において，データが一度別の表現に置き換わる事を利用してデータの特徴抽出，ディープニューラルネットの事前学習などに用いられる．

一般的な自己符号化器では，図のような単層のニューラルネット(入力層と出力層のみからなるニューラルネット)を折り返したものを使用する．

このとき入力層から中間層への計算は，重み行列を\\(\mathbf{W}\\)，バイアスを\\(\mathbf{b}\\)，

\\[ \mathbf{y}(\mathbf{x}) = f(\mathbf{W}\mathbf{x} + \mathbf{b}) \\]


\\[
 \hat{\mathbf{x}}(\mathbf{x}) = \tilde{f}(\tilde{\mathbf{W}}  f(\mathbf{W}\mathbf{x} + \mathbf{b} )  + \tilde{\mathbf{b}})
\\] 



このように単層の自己符号化器を積み重ねたものを **積層自己符号化器** と呼ぶ．


# 5.7 その他の自己符号化器

#### 多層自己符号化器

ディープネットの事前学習を行う際，単層に分割して層ごとに自己符号化器を複数作るのではなく，ディープネットの出力のひとつ前で折り返して自己符号化器を作ることもできる．

しかし単純に考えて元のディープネットの2倍近くの深さになり，学習が困難になることが多い．
