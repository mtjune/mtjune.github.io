---
layout: post
title:  "自己符号化器"
date:   2015-12-01 02:00:00 +0900
categories: DeepLearning
---
Deep Learning勉強会 第4回


# 5.1 概要


$$
\delta_l^{(l)} = \left\{ \sum_k \delta_k^{(l+1)} w_{kj}^{(l+1)} + \beta \left( - \frac{\rho}{\hat{\rho}_j} + \frac{1-\rho}{1-\hat{\rho}_j} \right) \right\} f'(u_j^{(l)})
$$

自己符号化器はニューラルネットにおいて，目標とする出力(正解データ)を入力と同じにした教師なし学習を行うときに用いられるモデル．

自己符号化器の中間層において，データが一度別の表現に置き換わる事を利用してデータの特徴抽出，ディープニューラルネットの事前学習などに用いられる．

一般的な自己符号化器では，図のような単層のニューラルネット(入力層と出力層のみからなるニューラルネット)を折り返したものを使用する．

このとき入力層から中間層への計算は，重み行列を\\(\mathbf{W}\\)，バイアス
